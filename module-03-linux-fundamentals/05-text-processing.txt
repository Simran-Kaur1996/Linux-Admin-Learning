- cut, awk, grep, sort, uniq, wc
Filters / Text processors Commands

=========================
Linux Text Processing Commands
=========================

1. CUT – Extract specific fields or characters
---------------------------------------------
- Use: Select columns or fields from text
- Common Options:
  - `-d` : delimiter (default is tab)
  - `-f` : field number(s)
  - `-c` : character position(s)

Examples:
  cut -d',' -f1 file.txt       → First column from CSV
  cut -c1-5 filename.txt       → Characters 1 to 5 from each line

Use case: Extract usernames from a passwd file
  cut -d':' -f1 /etc/passwd


2. AWK – Pattern scanning and processing
----------------------------------------
- Use: Powerful text filter, works line by line
- Format: awk 'pattern {action}' file

Examples:
  awk '{print $1}' file.txt           → Print first field of each line
  awk -F':' '{print $1,$3}' /etc/passwd → Username and UID

Use case: Sum numbers in 2nd column
  awk '{sum += $2} END {print sum}' file.txt


3. GREP – Search for patterns
-----------------------------
- Use: Find matching lines using regex
- Common Options:
  - `-i` : case-insensitive
  - `-v` : invert match
  - `-r` : recursive search
  - `-n` : show line numbers
  - `-E` : extended regex

Examples:
  grep "error" logfile.txt              → Search for “error”
  grep -i "fail" report.txt             → Case-insensitive search
  grep -v "OK" results.txt              → Exclude lines with "OK"
  grep -r "main()" ./src/               → Recursive search in directory


4. SORT – Sort lines in files
-----------------------------
- Use: Sorts text lines alphabetically or numerically
- Common Options:
  - `-n` : numeric sort
  - `-r` : reverse sort
  - `-k` : sort by key/column
  - `-t` : delimiter

Examples:
  sort file.txt                         → Sort alphabetically
  sort -n marks.txt                     → Sort numerically
  sort -t',' -k2 file.csv               → Sort CSV by 2nd column


5. UNIQ – Remove duplicate lines
-------------------------------
- Use: Filters out repeated lines (adjacent only!)
- Usually used with sort
- Common Options:
  - `-c` : count duplicates
  - `-d` : show only duplicates
  - `-u` : show only unique lines

Examples:
  sort names.txt | uniq                 → Remove duplicates
  sort names.txt | uniq -c              → Show count of each line
  sort file.txt | uniq -u              → Unique lines only


6. WC – Word/line/character count
---------------------------------
- Use: Count words, lines, bytes, characters
- Options:
  - `-l` : lines
  - `-w` : words
  - `-c` : bytes
  - `-m` : characters

Examples:
  wc file.txt                           → Show all counts
  wc -l *.txt                           → Line count per file
  cat file.txt | wc -w                  → Word count

Use case: Count number of lines with 'error'
  grep "error" logfile.txt | wc -l

===============================
CHAINING FILTERS EXAMPLE
===============================

Find how many unique users accessed a server:

  cut -d' ' -f1 access.log | sort | uniq | wc -l

Explanation:
  - `cut`: Get IP/username
  - `sort`: Prepare for uniq
  - `uniq`: Remove duplicates
  - `wc -l`: Count unique entries

===============================
